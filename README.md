# 2024-NC2-M19-MachineLearning

## ğŸ¥ Youtube Link

(ì¶”í›„ ë§Œë“¤ì–´ì§„ ìœ íŠœë¸Œ ë§í¬ ì¶”ê°€) <br/>

## ğŸ’¡ About Augmented Reality

>  **Core ML** : AI ëª¨ë¸ì„ Apple ë””ë°”ì´ìŠ¤ì™€ ì‰½ê²Œ í†µí•©í•  ìˆ˜ ìˆê²Œ í•˜ëŠ” ê°•ë ¥í•œ í”„ë ˆì„ì›Œí¬ <br/>
>  **Create ML** : ì½”ë“œì‘ì„± ì—†ì´ë„, ì›í•˜ëŠ” AI ëª¨ë¸ì„ ì‰½ê²Œ ë§Œë“¤ì–´ì£¼ëŠ” ë„êµ¬
> 
> <img width="1841" alt="MLá„‰á…©á„€á…¢" src="https://github.com/DeveloperAcademy-POSTECH/2024-NC2-M19-MachineLearning/assets/156973592/0f461bb5-d45d-4cfc-ae17-6bdededda83b">
> 
> MLì˜ **4ê°€ì§€ ë¶„ë¥˜**
> - Vision: ì»´í“¨í„° ë¹„ì „ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì™€ ë¹„ë””ì˜¤ë¥¼ ì²˜ë¦¬í•˜ê³  ë¶„ì„
> - Natural Language: ë‹¨ì–´ í¬í•¨, ë¶„ë¥˜ì™€ ê°™ì€ ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ê³  ì´í•´
> - Speech: ë‹¤ì–‘í•œ ì–¸ì–´ì— ëŒ€í•œ ìŒì„± ì¸ì‹ ë° í˜„ì €ì„± ê¸°ëŠ¥ì„ í™œìš©
> - Sound: ì˜¤ë””ì˜¤ë¥¼ ë¶„ì„í•˜ê³  ì›ƒìŒì´ë‚˜ ë°•ìˆ˜ê°™ì€ íŠ¹ì • ìœ í˜•ìœ¼ë¡œ ë¶„ë¥˜/ì¸ì‹ <br/>

## ğŸ¯ What we focus on?

> Create MLì—ì„œ Image Classification í…œí”Œë¦¿ì„ í™œìš©í•˜ì—¬ ì§ì ‘ AI ëª¨ë¸ì„ ë§Œë“¤ê³ , Vision í”„ë ˆì„ì›Œí¬ì¸ VNCoreMLContainerë¥¼ í™œìš©í•˜ì—¬ ì§ì ‘ ë§Œë“  ML ëª¨ë¸ì„ ì•±ì— ì ìš©í•œë‹¤. <br/>

## ğŸ’¼ Use Case
> **ğŸ˜½ í¬ìŠ¤í… ê³ ì–‘ì´ë“¤ì„ êµ¬ë¶„í•˜ê³  ë§Œë‚œ ê³ ì–‘ì´ë“¤ì„ ê¸°ë¡í•˜ì!** <br/>

## ğŸ–¼ï¸ Prototype

<img width="1247" alt="prototype" src="https://github.com/DeveloperAcademy-POSTECH/2024-NC2-M19-MachineLearning/assets/156973592/57015213-4537-427f-b256-4228af19cd7e">

[RPReplay_Final1718841098.MP4](https://prod-files-secure.s3.us-west-2.amazonaws.com/2e999faf-43aa-426e-ba81-0a9f876c0c58/669ae909-aed9-494d-877e-bd511374bf7e/RPReplay_Final1718841098.mp4)
<br/>

## ğŸ› ï¸ About Code
```swift
import Vision

extension MosuDataModel {
    func detect(image: CIImage, completion: @escaping (String) -> Void) {

        // CoreMLì˜ ëª¨ë¸ë¡œ ì‚¬ìš©í•  PocatClassifier2ë¥¼ coreMLModel ê°ì²´ë¡œ ìƒì„± í›„,
        // Vision í”„ë ˆì„ì›Œí¬ì¸ VNCoreMLModel ì»¨í…Œì´ë„ˆë¥¼ ì‚¬ìš©í•˜ì—¬ CoreMLì˜ modelì— ì ‘ê·¼í•œë‹¤.
        guard let coreMLModel = try? PocatClassifier2(configuration: MLModelConfiguration()),
              let visionModel = try? VNCoreMLModel(for: coreMLModel.model) else {
            fatalError("Loading CoreML Model Failed")
        }

        // Visionì„ ì´ìš©í•´ ì´ë¯¸ì¹˜ ì²˜ë¦¬ë¥¼ ìš”ì²­
        let request = VNCoreMLRequest(model: visionModel) { request, error in
            guard error == nil else {
                fatalError("Failed Request")
            }

            // ì‹ë³„ìì˜ ì´ë¦„(ê³ ì–‘ì´ ì´ë¦„)ì„ í™•ì¸í•˜ê¸° ìœ„í•´ VNClassificationObservationë¡œ ë³€í™˜í•´ì¤€ë‹¤.
            guard let classification = request.results as? [VNClassificationObservation] else {
                fatalError("Faild convert VNClassificationObservation")
            }

            // ë¨¸ì‹ ëŸ¬ë‹ì„ í†µí•œ ê²°ê³¼ê°’ í”„ë¦°íŠ¸
            print(classification)
            if let firstItem = classification.first { // ê°€ì¥ í™•ë¥ ì´ ë†’ì€ ê²°ê³¼ë¥¼ firstItemì— ì €ì¥
                print(firstItem.identifier.capitalized)
                var result = firstItem.identifier.capitalized
                result += " "
                result += firstItem.confidence.formatted()
                completion(firstItem.identifier.capitalized)
            } else {
                completion("ëª»ì°¾ìŒ ã… ")
            }
        }

        // ì´ë¯¸ì§€ë¥¼ ë°›ì•„ì™€ì„œ performì„ ìš”ì²­í•˜ì—¬ ë¶„ì„í•œë‹¤. (Vision í”„ë ˆì„ì›Œí¬)
        let handler = VNImageRequestHandler(ciImage: image)
        do {
            try handler.perform([request])
        } catch {
            print(error)
        }
    }
}
```
